html_nodes("strong") %>%
html_nodes("a") %>%
html_attr("href")
hyperlink = hyperlink[-c(1,2)]
link_name = webpage %>%
html_nodes("article") %>%
html_nodes("h2") %>%
html_text()
link_name = link_name[-c(1)]
City_to_link = data.frame(link_name, hyperlink)
write.table(City_to_link, file = "links_v_cities.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
library("XML") # Parsing XML files
library(plyr)  # rbind.fill
result = data.frame()
for (cities_URL in City_to_link$hyperlink){
print(i)
download.file(cities_URL, destfile = "Temp_dir/temp.xml")
xml_content = xmlParse(file = "Temp_dir/temp.xml")
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xml_dataframe = cbind(xml_dataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xml_dataframe = cbind(xml_dataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
result = rbind.fill(result, xml_dataframe)
}
library("XML") # Parsing XML files
library(plyr)  # rbind.fill
result = data.frame()
for (cities_URL in City_to_link$hyperlink){
download.file(cities_URL, destfile = "Temp_dir/temp.xml")
xml_content = xmlParse(file = "Temp_dir/temp.xml")
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xml_dataframe = cbind(xml_dataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xml_dataframe = cbind(xml_dataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
result = rbind.fill(result, xml_dataframe)
}
library("XML") # Parsing XML files
library(plyr)  # rbind.fill
result = data.frame()
for (cities_URL in City_to_link$hyperlink){
download.file(cities_URL, destfile = "Temp_dir/temp.xml")
xml_content = xmlParse(file = "Temp_dir/temp.xml")
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
result = rbind.fill(result, xmldataframe)
}
saveRDS(result, file = "final_result.rds")
View(result)
colnames(result)
class(colnames(result))
result$RightToReply
str(result$RightToReply)
length(which(result$RightToReply != NA))
length(which(result$RightToReply == NA))
which(result$RightToReply == NA)
which(result$RightToReply ~= NA)
which(result$RightToReply != NA)
which(is.na(result$RightToReply))
length(which(is.na(result$RightToReply)))
length(which(!is.na(result$RightToReply)))
which(!is.na(result$RightToReply))
result$RightToReply[which(!is.na(result$RightToReply))]
colnames(result)
result = result[,c(1:5, 19, 6:18, 20:25)]
saveRDS(result, file = "final_result.rds")
test_result = data.frame()
route = list.files("../Hygiene_Cities/XML/")
i = 1
for (cities_URL in route){
print(i)
xml_content = xmlParse(file = paste0("../Hygiene_Cities/XML/", "Temp_dir/temp.xml"))
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
test_result = rbind.fill(test_result, xmldataframe)
}
test_result = data.frame()
route = list.files("../Hygiene_Cities/XML/")
i = 1
for (cities_URL in route){
print(i)
xml_content = xmlParse(file = paste0("../Hygiene_Cities/XML/", cities_URL))
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
test_result = rbind.fill(test_result, xmldataframe)
}
library(parallel)
numCores <- detectCores()
library(parallel)
numCores <- detectCores()
test_result = data.frame()
route = list.files("../Hygiene_Cities/XML/")
i = 1
mclapply(
for (cities_URL in route){
print(i)
xml_content = xmlParse(file = paste0("../Hygiene_Cities/XML/", cities_URL))
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
test_result = rbind.fill(test_result, xmldataframe)
i = i + 1
}, mc.cores = numCores
)
library(doParallel)
install.packages("doParallel")
library(doParallel)
library(doParallel)
numCores <- detectCores()
test_result = data.frame()
route = list.files("../Hygiene_Cities/XML/")
i = 1
cl <- makeCluster(cores[1]-1)
library(doParallel)
numCores <- detectCores()
test_result = data.frame()
route = list.files("../Hygiene_Cities/XML/")
i = 1
cl <- makeCluster(numCores[1]-1)
registerDoParallel(cl)
for (cities_URL in route){
print(i)
xml_content = xmlParse(file = paste0("../Hygiene_Cities/XML/", cities_URL))
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
test_result = rbind.fill(test_result, xmldataframe)
i = i + 1
}
stopCluster(cl)
final_result = readRDS("rdadata/olist_customers_dataset.rds")
final_result = readRDS("./final_result.rds")
final_result = readRDS("./final_result.rds")
View(final_result)
colnames(final_result)
test_result = unite(final_result, AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = " ", remove = TRUE)
library(tidyr)
test_result = unite(final_result, AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = " ", remove = TRUE)
View(test_result)
library(tidyr)
test_result = unite(final_result, AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = " ", remove = TRUE, na.rm = TRUE)
library(tidyr)
test_result = unite(final_result, AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = ", ", remove = TRUE, na.rm = TRUE)
View(test_result)
final_result = tidyr::unite(final_result, AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = ", ", remove = TRUE, na.rm = TRUE)
rm(test_result)
saveRDS(final_result, file = "final_result.rds")
View(final_result)
View(final_result)
xmlParse("../Hygiene_Cities/XML/Aberdeen City.xml")
library("XML")
xmlParse("../Hygiene_Cities/XML/Aberdeen City.xml")
View(final_result)
View(final_result)
View(final_result)
knitr::opts_chunk$set(echo = TRUE)
hyperlink = webpage %>%
html_nodes("strong") %>%
html_nodes("a") %>%
html_attr("href")
# install.packages('rvest')
library(rvest)
webpage = read_html("https://data.food.gov.uk/catalog/datasets/38dd8d6a-5ab1-4f50-b753-ab33288e3200")
hyperlink = webpage %>%
html_nodes("strong") %>%
html_nodes("a") %>%
html_attr("href")
hyperlink = hyperlink[-c(1,2)]
hyperlink
View(final_result)
hyperlink
View(final_result)
xmlParse(file = "Temp_dir/temp.xml")
library(XML)
xmlParse(file = "Temp_dir/temp.xml")
View(final_result)
View(final_result)
xmlToDataFrame(getNodeSet(xml_content, "//Scores"))
knitr::opts_chunk$set(echo = TRUE)
library("XML") # Parsing XML files
library(plyr)  # rbind.fill
xmlToDataFrame(getNodeSet(xml_content, "//Scores"))
hyperlink
download.file("http://ratings.food.gov.uk/OpenDataFiles/FHRS323en-GB.xml", destfile = "temp.xml")
xml_content = xmlParse(file = "temp.xml")
test = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
View(test)
xmldataframe[,c("Scores")] = NULL
test[,c("Scores")] = NULL
download.file("http://ratings.food.gov.uk/OpenDataFiles/FHRS323en-GB.xml", destfile = "temp.xml")
xml_content = xmlParse(file = "temp.xml")
test = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
download.file("https://ratings.food.gov.uk/OpenDataFiles/FHRS760en-GB.xml", destfile = "temp.xml")
xml_content = xmlParse(file = "temp.xml")
test = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
test[,c("Scores")] = NULL
xmlToDataFrame(getNodeSet(xml_content, "//Scores"))
try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)
class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE))
download.file("https://ratings.food.gov.uk/OpenDataFiles/FHRS323en-GB.xml", destfile = "temp.xml")
xml_content = xmlParse(file = "temp.xml")
test = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
test[,c("Scores")] = NULL
class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE))
download.file("https://ratings.food.gov.uk/OpenDataFiles/FHRS760en-GB.xml", destfile = "temp.xml")
xml_content = xmlParse(file = "temp.xml")
test = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
test[,c("Scores")] = NULL
try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = F)
try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = T)
class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE))
class(class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)))
?tidyverse
library(tidyverse)
?saveRDS
View(final_result)
final_result %>% select(RatingValue)
library(tidyverse)
final_result %>% select(RatingValue)
url = "https://data.food.gov.uk/catalog/datasets/38dd8d6a-5ab1-4f50-b753-ab33288e3200"
link <- read_html(url) %>% html_nodes("strong") %>% html_nodes("a") %>% html_attr('href')
#pick links
link = link[which(grepl(pattern= "OpenDataFiles", link))]
#which() for choosing what pattern you want
library("rvest")
url = "https://data.food.gov.uk/catalog/datasets/38dd8d6a-5ab1-4f50-b753-ab33288e3200"
link <- read_html(url) %>% html_nodes("strong") %>% html_nodes("a") %>% html_attr('href')
#pick links
link = link[which(grepl(pattern= "OpenDataFiles", link))]
#which() for choosing what pattern you want
link
View(final_result)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
a = read_csv("Final_format_files/Aberdeen City.csv")
b = final_result %>%
filter(LocalAuthorityName == "Aberdeen City")
library(tidyverse)
b = final_result %>%
filter(LocalAuthorityName == "Aberdeen City")
c = which(a$FHRSID != b$FHRSID)
c
c = which(a$FHRSID %in% b$FHRSID)
c
c = which(b$FHRSID %in% a$FHRSID)
c
c = which(b$FHRSID !%in% a$FHRSID)
c = which(b$FHRSID -%in% a$FHRSID)
c = which(b$FHRSID not %in% a$FHRSID)
c = b %>%
filter(FHRSID %in% a$FHRSID)
View(c)
c = b %>%
filter(!FHRSID %in% a$FHRSID)
View(c)
# install.packages('rvest')
library(rvest)
webpage = read_html("https://data.food.gov.uk/catalog/datasets/38dd8d6a-5ab1-4f50-b753-ab33288e3200")
hyperlink = webpage %>%
html_nodes("strong") %>%
html_nodes("a") %>%
html_attr("href")
hyperlink = hyperlink[-c(1,2)]
link_name = webpage %>%
html_nodes("article") %>%
html_nodes("h2") %>%
html_text()
link_name = link_name[-c(1)]
City_to_link = data.frame(link_name, hyperlink)
write.table(City_to_link, file = "links_v_cities.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
library("XML") # Parsing XML files
library(plyr)  # rbind.fill
final_result = data.frame()
for (cities_URL in City_to_link$hyperlink){
download.file(cities_URL, destfile = "Temp_dir/temp.xml")
xml_content = xmlParse(file = "Temp_dir/temp.xml")
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
final_result = rbind.fill(final_result, xmldataframe)
}
final_result = final_result[,c(1:5, 19, 6:18, 20:25)] %>%
tidyr::unite(AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = ", ", remove = TRUE, na.rm = TRUE)
saveRDS(final_result, file = "final_result.rds")
a = readRDS("final_result.rds")
d = readRDS("final_result.rds")
View(d)
rm(a,b,c)
View(City_to_link)
knitr::opts_chunk$set(echo = TRUE)
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(cities_URL, destfile = "ALL_XML_dir/")
}
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(City_to_link$hyperlink[i], destfile = "file_path")
}
for (i in 1:nrow(City_to_link)){
print(i)
}
for (i in 1:nrow(City_to_link)){
print(City_to_link$link_name[i])
}
for (i in 1:nrow(City_to_link)){
print(City_to_link$hyperlink[i])
}
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(City_to_link$hyperlink[i], destfile = file_path)
}
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("./ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(City_to_link$hyperlink[i], destfile = file_path)
}
str(City_to_link)
City_to_link$link_name[1]
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("~/ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(City_to_link$hyperlink[i], destfile = file_path)
}
a = City_to_link$link_name
link_name
gsub("[\n]", "", link_name)
# Combine cities and hyperlinks into a dataframe
City_to_link = data.frame(link_name, hyperlink)
# Create a txt file to record all city names and their corresponding hyperlinks
write.table(City_to_link, file = "links_v_cities.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
a = City_to_link$link_name
link_name
gsub("[\n]", "", link_name)
link_name = gsub("[\n]", "", link_name)
# Combine cities and hyperlinks into a dataframe
City_to_link = data.frame(link_name, hyperlink)
# Create a txt file to record all city names and their corresponding hyperlinks
write.table(City_to_link, file = "links_v_cities.txt", sep = "\t", row.names = FALSE, col.names = FALSE)
a = City_to_link$link_name
City_to_link$link_name
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("~/ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(City_to_link$hyperlink[i], destfile = file_path)
}
# Please create a directory called ALL_XML_dir or if downloading all xml files in the current directory it
# would be very messy
for (i in 1:nrow(City_to_link)){
file_path = paste0("./ALL_XML_dir/", City_to_link$link_name[i], ".xml")
download.file(City_to_link$hyperlink[i], destfile = file_path)
}
local_xml_path = list.files("ALL_XML_dir/")
local_xml_path
# Get xml path from local directory ALL_XML_dir
local_xml_path = list.files("ALL_XML_dir/")
# Create an empty data frame
final_result = data.frame()
# Start parsing xml files
for (path in local_xml_path){
xml_content = xmlParse(file = path)
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
final_result = rbind.fill(final_result, xmldataframe)
}
library("XML") # Parsing XML files
library(plyr)  # rbind.fill
# Get xml path from local directory ALL_XML_dir
local_xml_path = list.files("ALL_XML_dir/")
# Create an empty data frame
final_result = data.frame()
# Start parsing xml files
for (path in local_xml_path){
xml_content = xmlParse(file = path)
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
final_result = rbind.fill(final_result, xmldataframe)
}
view(local_xml_path)
View(local_xml_path)
for (i in local_xml_path)(print(i))
path = paste0("ALL_XML_dir/", local_xml_path[1])
paht
path
xml_content = xmlParse(file = path)
# Start parsing xml files
for (i in local_xml_path){
path = paste0("ALL_XML_dir/", i)
xml_content = xmlParse(file = path)
xmldataframe = xmlToDataFrame(getNodeSet(xml_content, "//EstablishmentDetail"))
# deal with the tag Scores
xmldataframe[,c("Scores")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Scores")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Scores")))
}
# deal with the tag Geocode
xmldataframe[,c("Geocode")] = NULL
if (class(try(xmlToDataFrame(getNodeSet(xml_content, "//Geocode")), silent = TRUE)) != "try-error"){
xmldataframe = cbind(xmldataframe, xmlToDataFrame(getNodeSet(xml_content, "//Geocode")))
}
final_result = rbind.fill(final_result, xmldataframe)
}
## Reorder columns and combine AddressLine1 ~ AddressLine4 as AddressLine
final_result = final_result[,c(1:5, 19, 6:18, 20:25)] %>%
tidyr::unite(AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = ", ", remove = TRUE, na.rm = TRUE)
## Reorder columns and combine AddressLine1 ~ AddressLine4 as AddressLine
library(tidyverse)
final_result = final_result[,c(1:5, 19, 6:18, 20:25)] %>%
tidyr::unite(AddressLine, AddressLine1, AddressLine2, AddressLine3, AddressLine4, sep = ", ", remove = TRUE, na.rm = TRUE)
# Save our data into a rds file for part D
saveRDS(final_result, file = "final_result.rds")
All_data = readRDS("final_result.rds")
?rvest
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
?rvest
View(City_to_link)
